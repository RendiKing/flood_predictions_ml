{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba74967a",
   "metadata": {},
   "source": [
    "Kaggle Competition\n",
    "UNT HydroInsight 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbefa4f",
   "metadata": {},
   "source": [
    "Group: \n",
    "Rendi King\n",
    "Namita Victor\n",
    "Lakshmi Triveni Muthyala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7abbaa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4185c9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35000 entries, 0 to 34999\n",
      "Data columns (total 27 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   MonsoonIntensity                 35000 non-null  int64  \n",
      " 1   TopographyDrainage               35000 non-null  int64  \n",
      " 2   RiverManagement                  35000 non-null  int64  \n",
      " 3   Deforestation                    35000 non-null  int64  \n",
      " 4   Urbanization                     35000 non-null  int64  \n",
      " 5   ClimateChange                    35000 non-null  int64  \n",
      " 6   DamsQuality                      35000 non-null  int64  \n",
      " 7   Siltation                        35000 non-null  int64  \n",
      " 8   AgriculturalPractices            35000 non-null  int64  \n",
      " 9   Encroachments                    35000 non-null  int64  \n",
      " 10  IneffectiveDisasterPreparedness  35000 non-null  int64  \n",
      " 11  DrainageSystems                  35000 non-null  int64  \n",
      " 12  CoastalVulnerability             35000 non-null  int64  \n",
      " 13  Landslides                       35000 non-null  int64  \n",
      " 14  Watersheds                       35000 non-null  int64  \n",
      " 15  DeterioratingInfrastructure      35000 non-null  int64  \n",
      " 16  PopulationScore                  35000 non-null  int64  \n",
      " 17  WetlandLoss                      35000 non-null  int64  \n",
      " 18  InadequatePlanning               35000 non-null  int64  \n",
      " 19  PoliticalFactors                 35000 non-null  int64  \n",
      " 20  FloodProbability                 35000 non-null  float64\n",
      " 21  RegionType                       35000 non-null  object \n",
      " 22  FloodZoneRisk                    35000 non-null  object \n",
      " 23  ElevationDifference              35000 non-null  float64\n",
      " 24  RoadDensity                      35000 non-null  float64\n",
      " 25  AirPollutionIndex                35000 non-null  float64\n",
      " 26  RegionIndex                      35000 non-null  object \n",
      "dtypes: float64(4), int64(20), object(3)\n",
      "memory usage: 7.2+ MB\n",
      "None\n",
      "\n",
      "Test Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 26 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   MonsoonIntensity                 15000 non-null  int64  \n",
      " 1   TopographyDrainage               15000 non-null  int64  \n",
      " 2   RiverManagement                  15000 non-null  int64  \n",
      " 3   Deforestation                    15000 non-null  int64  \n",
      " 4   Urbanization                     15000 non-null  int64  \n",
      " 5   ClimateChange                    15000 non-null  int64  \n",
      " 6   DamsQuality                      15000 non-null  int64  \n",
      " 7   Siltation                        15000 non-null  int64  \n",
      " 8   AgriculturalPractices            15000 non-null  int64  \n",
      " 9   Encroachments                    15000 non-null  int64  \n",
      " 10  IneffectiveDisasterPreparedness  15000 non-null  int64  \n",
      " 11  DrainageSystems                  15000 non-null  int64  \n",
      " 12  CoastalVulnerability             15000 non-null  int64  \n",
      " 13  Landslides                       15000 non-null  int64  \n",
      " 14  Watersheds                       15000 non-null  int64  \n",
      " 15  DeterioratingInfrastructure      15000 non-null  int64  \n",
      " 16  PopulationScore                  15000 non-null  int64  \n",
      " 17  WetlandLoss                      15000 non-null  int64  \n",
      " 18  InadequatePlanning               15000 non-null  int64  \n",
      " 19  PoliticalFactors                 15000 non-null  int64  \n",
      " 20  RegionType                       15000 non-null  object \n",
      " 21  FloodZoneRisk                    15000 non-null  object \n",
      " 22  ElevationDifference              15000 non-null  float64\n",
      " 23  RoadDensity                      15000 non-null  float64\n",
      " 24  AirPollutionIndex                15000 non-null  float64\n",
      " 25  RegionIndex                      15000 non-null  object \n",
      "dtypes: float64(3), int64(20), object(3)\n",
      "memory usage: 3.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Uploaded files & Review Data\n",
    "train_file = 'floodprediction-comp.csv'  \n",
    "test_file = 'floodprediction-submission.csv'  \n",
    "\n",
    "train_data = pd.read_csv(train_file)\n",
    "test_data = pd.read_csv(test_file)\n",
    "\n",
    "print(\"Training Data Info:\")\n",
    "print(train_data.info())\n",
    "print(\"\\nTest Data Info:\")\n",
    "print(test_data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b00a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numeric vs non-numeric columns\n",
    "numeric_columns = train_data.select_dtypes(include=['number']).columns.drop('FloodProbability')\n",
    "non_numeric_columns = train_data.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "#Replace missing values in numeric columns with the median\n",
    "train_data[numeric_columns] = train_data[numeric_columns].fillna(train_data[numeric_columns].median())\n",
    "test_data[numeric_columns] = test_data[numeric_columns].fillna(test_data[numeric_columns].median())\n",
    "\n",
    "#Replace missing values in non-numeric columns with the mode\n",
    "for column in non_numeric_columns:\n",
    "    train_data[column].fillna(train_data[column].mode()[0], inplace=True)\n",
    "    if column in test_data.columns:\n",
    "        test_data[column].fillna(test_data[column].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba827a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "train_data = pd.get_dummies(train_data, columns=non_numeric_columns, drop_first=True)\n",
    "test_data = pd.get_dummies(test_data, columns=non_numeric_columns, drop_first=True)\n",
    "\n",
    "train_data, test_data = train_data.align(test_data, join='left', axis=1, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39c01c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate out the target variable\n",
    "X = train_data.drop(columns=['FloodProbability'])\n",
    "y = train_data['FloodProbability']\n",
    "\n",
    "#Drop Flood Probability from test_data\n",
    "if 'FloodProbability' in test_data.columns:\n",
    "    test_data = test_data.drop(columns=['FloodProbability'])\n",
    "\n",
    "#Align the training and testing datasets\n",
    "X, test_data = X.align(test_data, join='left', axis=1, fill_value=0)\n",
    "\n",
    "#Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Standardize numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "test_data_scaled = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832ec29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest model\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4e5108",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict and evaluate on validation data\n",
    "y_pred = rf.predict(X_val)\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "print(f\"Random Forest RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a89ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "test_predictions = rf.predict(test_data_scaled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
